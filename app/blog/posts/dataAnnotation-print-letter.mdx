---
title: 'Print Letter'
publishedAt: '2025-01-10'
summary: ''
number: ''
language: 'python'
---

## Print Letter
Print the letter from the given coordinates table.

Google doc url: 
https://docs.google.com/document/d/e/2PACX-1vRMx5YQlZNa3ra8dYYxmv-QIQ3YJe8tbI3kqcuC7lQiZm-CSEznKfN_HYNSpoXcZIV3Y_O3YoUB1ecq/pub
https://docs.google.com/document/d/e/2PACX-1vQGUck9HIFCyezsrBSnmENk5ieJuYwpt7YHYEzeNJkIb9OSDdx-ov2nRNReKQyey-cwJOoEKUhLmN9z/pub
 
## Solution
Approach 1:
````Python
import requests
from bs4 import BeautifulSoup

def extract_table_data(url):
    try:
        # Fetch the HTML response
        response = requests.get(url)
        if response.status_code != 200:
            print(f"Failed to retrieve the page. Status code: {response.status_code}")
            return

        # Parse the HTML content
        soup = BeautifulSoup(response.text, 'html.parser')

        # Find the first table
        table = soup.find('table')
        if not table:
            print("No table found on the page.")
            return
        
        # Extract rows and cells
        rows = table.find_all('tr')
        table_data = []
        for row in rows:
            cells = row.find_all(['td', 'th'])  # Include header cells if needed
            cell_values = [cell.get_text(strip=True) for cell in cells]
            table_data.append(cell_values)

        print_grid(table_data)

    except Exception as e:
        print(f"An error occurred: {e}")


def print_grid(data):
    # Parse the input data into x, y, and character
    grid_data = [(int(row[0]), row[1], int(row[2])) for row in data[1:]]

    # Determine the grid size
    max_x = max(item[0] for item in grid_data)
    max_y = max(item[2] for item in grid_data)

    # Create an empty grid filled with spaces
    grid = [[' ' for _ in range(max_x + 1)] for _ in range(max_y + 1)]

    # Populate the grid with characters
    for x, char, y in grid_data:
        grid[y][x] = char

    # Print the grid from top to bottom
    for row in reversed(grid):  # Flip the grid vertically
        print(''.join(row))


# URL of the Google Doc
url = ""

extract_table_data(url)

````